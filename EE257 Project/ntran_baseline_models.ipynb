{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE257 Project - Feature Extraction\n",
    "\n",
    "[Shoulder Implant X-Ray Manufacturer Classification Data Set (2020)](https://archive.ics.uci.edu/ml/datasets/Shoulder+Implant+X-Ray+Manufacturer+Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tickn\\\\ml\\\\EE257\\\\EE257 Project\\\\dataset'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "dataset_path = current_path + '\\dataset'\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 597 files belonging to 4 classes.\n",
      "Using 478 files for training.\n",
      "Found 597 files belonging to 4 classes.\n",
      "Using 119 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and split\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(dataset_path + '\\data')\n",
    "batch_size = 32\n",
    "\n",
    "def describe_img(filepath):\n",
    "    rand_img = random.choice(list(filepath.glob('**\\*.jpg')))\n",
    "    width, height = Image.open(str(rand_img)).size\n",
    "\n",
    "    return width, height\n",
    "\n",
    "img_width, img_height = describe_img(data_dir)\n",
    "\n",
    "# load image dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 123,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size = (img_height , img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 123,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size = (img_height , img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 62500)\n",
      "(478,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dataset_to_2D(dataset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for img_batch, label_batch in dataset:\n",
    "        # flatten images since model fit() needs 2D input\n",
    "        for img in img_batch:\n",
    "            x.append(img.flatten())\n",
    "        for label in label_batch:\n",
    "            y.append(label)\n",
    "    return x, y\n",
    "        \n",
    "x_train, y_train = dataset_to_2D(train_ds.as_numpy_iterator())\n",
    "x_test, y_test = dataset_to_2D(test_ds.as_numpy_iterator())\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 -- Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='newton-cg',max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='newton-cg')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 5  8  2  0]\n",
      " [ 1 36  8 16]\n",
      " [ 1  4  3 10]\n",
      " [ 3 12  2  8]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.50      0.33      0.40        15\n",
      "       Depuy       0.60      0.59      0.60        61\n",
      "     Tornier       0.20      0.17      0.18        18\n",
      "      Zimmer       0.24      0.32      0.27        25\n",
      "\n",
      "    accuracy                           0.44       119\n",
      "   macro avg       0.38      0.35      0.36       119\n",
      "weighted avg       0.45      0.44      0.44       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logreg_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, logreg_pred))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, logreg_pred, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 1.000000 \n",
      " Test error: 0.436975 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %model.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 7  5  1  2]\n",
      " [ 6 42  5  8]\n",
      " [ 3  5  2  8]\n",
      " [ 1 12  3  9]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.41      0.47      0.44        15\n",
      "       Depuy       0.66      0.69      0.67        61\n",
      "     Tornier       0.18      0.11      0.14        18\n",
      "      Zimmer       0.33      0.36      0.35        25\n",
      "\n",
      "    accuracy                           0.50       119\n",
      "   macro avg       0.40      0.41      0.40       119\n",
      "weighted avg       0.49      0.50      0.49       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "tree_predict = tree.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, tree_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, tree_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 1.000000 \n",
      " Test error: 0.504202 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %tree.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %tree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 5  7  1  2]\n",
      " [ 3 48  1  9]\n",
      " [ 2 10  0  6]\n",
      " [ 4 12  1  8]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.36      0.33      0.34        15\n",
      "       Depuy       0.62      0.79      0.70        61\n",
      "     Tornier       0.00      0.00      0.00        18\n",
      "      Zimmer       0.32      0.32      0.32        25\n",
      "\n",
      "    accuracy                           0.51       119\n",
      "   macro avg       0.33      0.36      0.34       119\n",
      "weighted avg       0.43      0.51      0.47       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# increase baseline budget to 10, was getting warning with default value\n",
    "svm = SVC(C=10)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "svm_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, svm_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, svm_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 0.933054 \n",
      " Test error: 0.512605 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %svm.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %svm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 7  6  1  1]\n",
      " [ 2 41  4 14]\n",
      " [ 0 10  1  7]\n",
      " [ 3 13  4  5]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.58      0.47      0.52        15\n",
      "       Depuy       0.59      0.67      0.63        61\n",
      "     Tornier       0.10      0.06      0.07        18\n",
      "      Zimmer       0.19      0.20      0.19        25\n",
      "\n",
      "    accuracy                           0.45       119\n",
      "   macro avg       0.36      0.35      0.35       119\n",
      "weighted avg       0.43      0.45      0.44       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model  -- LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "\n",
    "lda_predict = lda.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, lda_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, lda_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 0.887029 \n",
      " Test error: 0.453782 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %lda.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %lda.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 5  7  1  2]\n",
      " [ 1 53  0  7]\n",
      " [ 0 10  0  8]\n",
      " [ 1 20  0  4]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.71      0.33      0.45        15\n",
      "       Depuy       0.59      0.87      0.70        61\n",
      "     Tornier       0.00      0.00      0.00        18\n",
      "      Zimmer       0.19      0.16      0.17        25\n",
      "\n",
      "    accuracy                           0.52       119\n",
      "   macro avg       0.37      0.34      0.33       119\n",
      "weighted avg       0.43      0.52      0.45       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "rand_forest.fit(x_train, y_train)\n",
    "\n",
    "forest_predict = rand_forest.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, forest_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, forest_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 1.000000 \n",
      " Test error: 0.521008 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %rand_forest.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %rand_forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried different baseline models:\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* SVM\n",
    "* LDA\n",
    "* Random Forest\n",
    "\n",
    "All models except for LDA are overfitting on training data. \n",
    "\n",
    "Best test accuracy (ranked descending order):\n",
    "* SVM -- 51.26%\n",
    "* Random Forest -- 52.1%\n",
    "* Decision Tree -- 50.42%\n",
    "* LDA -- 45.38%\n",
    "* Log Reg -- 43.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps are:\n",
    "* perform feature selection through Ridge / Lasso regularization\n",
    "* reduce overfitting on training data to improve test performance\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6945c16a0984d1ac9e5b0055ebd9257e73620e552f2c1a12e2e737359eca363"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
